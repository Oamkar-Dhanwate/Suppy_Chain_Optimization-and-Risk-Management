# ğŸ“¦ Supply Chain Optimization & Risk Management Dashboard

A comprehensive **data-driven dashboard** built with **Python** and **Streamlit** to analyze supply chain performance, predict late delivery risks, and provide actionable insights for logistics management.

---

## ğŸš€ Live Demo  
[Add your Streamlit Community Cloud deployment link here]

---

## âœ¨ Key Features
- **Executive KPIs**: Quick insights with OTIF (On-Time-In-Full) Rate & Perfect Order Rate.  
- **Interactive Analytics**: Dynamic charts & geographical heatmaps to spot high-risk regions.  
- **ML-Powered Risk Prediction**: Real-time late delivery risk detection with Random Forest.  
- **Optimal Shipping Recommendation**: Suggests best shipping mode balancing risk & profit.  
- **Dynamic Filtering & Export**: Filter by region, mode, date & export results as CSV.  

---

## ğŸ“¸ Dashboard Preview  
(Add a screenshot of your running dashboard here)

---

## ğŸ“‚ Project Structure
supply_chain_optimization/
â”œâ”€â”€ ğŸ“‚ dashboard/
â”‚   â””â”€â”€ ğŸ“„ app.py              # Main Streamlit application
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â””â”€â”€ ğŸ“„ raw/                 # Raw dataset
â”œâ”€â”€ ğŸ“‚ notebooks/                # Jupyter notebooks for analysis & modeling
â”œâ”€â”€ ğŸ“‚ src/                      # Source code for the data pipeline
â”‚   â”œâ”€â”€ ğŸ“¦ data/
â”‚   â”œâ”€â”€ ğŸ“¦ features/
â”‚   â””â”€â”€ ğŸ“¦ models/
â”œâ”€â”€ ğŸ“„ run_pipeline.py           # Master script to run the backend
â””â”€â”€ ğŸ“„ requirements.txt           # Project dependencies

---

## ğŸ›  Tech Stack
- **Backend**: Python, Pandas, Scikit-learn  
- **Machine Learning**: Random Forest (classification), K-Means (segmentation), Prophet (forecasting)  
- **Dashboard**: Streamlit  
- **Visualization**: Plotly Express  

---

## âš™ï¸ How to Run Locally
```bash
# Clone the repository
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name

# Create & activate virtual environment
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run data pipeline (process data + train ML models)
python run_pipeline.py

# Launch dashboard
streamlit run dashboard/app.py
